# -*- coding: utf-8 -*-
"""CS412 Term Project Round 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k-dncnd8LLnD4TaxtdclHVdOEwP8TmRX
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import gzip
import json

from pprint import pprint
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
import re
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.model_selection import train_test_split

from sklearn.preprocessing import LabelEncoder
from transformers import BertTokenizer, TFBertForSequenceClassification
import tensorflow as tf

"""#Preprocessing"""

nltk.download('stopwords')
turkish_stopwords = stopwords.words('turkish')

my_classification_df = pd.read_csv("/content/drive/MyDrive/CS412 project/my_annotations.csv",)
my_classification_df = my_classification_df.rename(columns={'Unnamed: 0': 'user_id', 'influencerCategory': 'category'})
train_classification_df = pd.read_csv("/content/drive/MyDrive/CS412 project/train-classification.csv",)
train_classification_df = train_classification_df.rename(columns={'Unnamed: 0': 'user_id', 'label': 'category'})
train_classification_df.loc[train_classification_df['category'] == 'Health and lifestyle', 'category'] = 'Health and Lifestyle'

# Combine datasets
combined_df = pd.concat([train_classification_df, my_classification_df], ignore_index=True)

# Drop rows where 'category' is NaN or user_id is missing
combined_df.dropna(subset=['user_id', 'category'], inplace=True)

# Ensure all categories are strings
combined_df['category'] = combined_df['category'].astype(str).str.strip()

# Create unified dictionary
username2_category = combined_df.set_index("user_id")["category"].to_dict()

combined_df.groupby("category").count()

train_data_path = "/content/drive/MyDrive/CS412 project/training-dataset.jsonl.gz"

username2posts_train = dict()
username2profile_train = dict()

username2posts_test = dict()
username2profile_test = dict()


with gzip.open(train_data_path, "rt") as fh:
  for line in fh:
    sample = json.loads(line)

    profile = sample["profile"]
    username = profile["username"]
    if username in username2_category:
      # train data info
      username2posts_train[username] = sample["posts"]
      username2profile_train[username] = profile


    else:
      # it is test data info
      username2posts_test[username] = sample["posts"]
      username2profile_test[username] = profile

# Profile Dataframe
train_profile_df = pd.DataFrame(username2profile_train).T.reset_index(drop=True)
test_profile_df = pd.DataFrame(username2profile_test).T.reset_index(drop=True)

train_profile_df.head(2)

# Preprocess captions (keep emojis intact)
def preprocess_text(text: str):
    text = text.casefold()
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    text = re.sub(r'[^a-zçğıöşü0-9\s#@]', '', text)
    text = re.sub(r'\d+', '', text)        # Remove numbers
    text = re.sub(r'\s+', ' ', text).strip()
    return text


corpus = []

# to keep the label order
train_usernames = []

# Aggregate posts per user
for username, posts in username2posts_train.items():
    train_usernames.append(username)
    cleaned_captions = []
    for post in posts:
        post_caption = post.get("caption", "")
        if post_caption is None:
            continue

        post_caption = preprocess_text(post_caption)
        if post_caption != "":
            cleaned_captions.append(post_caption)

    user_post_captions = " \n ".join(cleaned_captions)
    corpus.append(user_post_captions)

"""#Random Forest"""

vectorizer = TfidfVectorizer(stop_words=turkish_stopwords, max_features=5000)
vectorizer.fit(corpus)

# transform the data into vectors
x_post_train = vectorizer.transform(corpus)
y_train = [username2_category.get(uname, "NA") for uname in train_usernames]


test_usernames = []
test_corpus = []
for username, posts in username2posts_test.items():
  test_usernames.append(username)
  # aggregating the posts per user
  cleaned_captions = []
  for post in posts:
    post_caption = post.get("caption", "")
    if post_caption is None:
      continue

    post_caption = preprocess_text(post_caption)

    if post_caption != "":
      cleaned_captions.append(post_caption)

  user_post_captions = "\n".join(cleaned_captions)
  test_corpus.append(user_post_captions)


# Just transforming! No Fitting!!!!!
x_post_test = vectorizer.transform(test_corpus)

assert y_train.count("NA") == 0

feature_names = vectorizer.get_feature_names_out()
feature_names

df_tfidf = pd.DataFrame(x_post_train.toarray(), columns=feature_names)
df_tfidf.head(2)

df_tfidf.shape

from sklearn.model_selection import train_test_split

x_train, x_val, y_train, y_val = train_test_split(df_tfidf, y_train, test_size=0.2, stratify=y_train ,random_state=42)

x_train.shape

x_val.shape

"""#User Classification
We use Random Forest along with vectorized contents to predict influencer type.
"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(RandomForestClassifier(), param_grid, scoring='accuracy', cv=5, n_jobs=-1)
grid_search.fit(x_train, y_train)

best_model = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)

rf_model = RandomForestClassifier(
    n_estimators=200,  # Number of trees
    random_state=42,   # For reproducibility
    max_depth=None,    # Expand trees until all leaves are pure or contain < min_samples_split samples
    min_samples_split=10,  # Minimum samples required to split an internal node
    n_jobs=-1          # Use all processors for parallel training
)

# Train the model
rf_model.fit(x_train, y_train)

# Evaluate on training set
y_train_pred= rf_model.predict(x_train)
print("Training Accuracy:", accuracy_score(y_train, y_train_pred))
print("\nTraining Classification Report:")
print(classification_report(y_train, y_train_pred))

# Evaluate on validation set
y_val_pred = rf_model.predict(x_val)
print("Validation Accuracy:", accuracy_score(y_val, y_val_pred))
print("\nValidation Classification Report:")
print(classification_report(y_val, y_val_pred))

"""##Test Data"""

def test_classification(input_file,output_file):
  #open_file
  test_data_path = "inputs/"+input_file
  test_unames = []
  with open(test_data_path, "rt") as fh:
    for line in fh:
      test_unames.append(line.strip())
  x_test = []
  if "screenname" in test_unames:
    test_unames.remove("screenname")
  for uname in test_unames:
    try:
      index = test_usernames.index(uname)
      x_test.append(x_post_test[index].toarray()[0])
    except Exception as e:
      try:
        index = train_usernames.index(uname)
        x_test.append(x_post_train[index].toarray()[0])
      except Exception as e:
        print(uname)
  df_test = pd.DataFrame(np.array(x_test), columns=feature_names)
  #make predictions
  test_pred = rf_model.predict(df_test)
  output = dict()
  for index, uname in enumerate(test_unames):
    output[uname] = test_pred[index]
  with open("outputs/"+output_file, "w") as of:
    json.dump(output, of, indent=4)

test_classification("test-classification-round1.dat","prediction-classification-round1.json")
test_classification("test-classification-round2.dat","prediction-classification-round2.json")
test_classification("test-classification-round3.dat","prediction-classification-round3.json")

"""# Like Count Prediction


Here, we use train a linear regression model with log like counts - avg log like counts(per user). I didn't use vectorized content for this as that would only confuse the model. Since we're trying to minimize log MSE, this seemed to be the best approach.
"""

import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import Ridge
from scipy.sparse import hstack
from datetime import datetime

# Get average like count for a user
def get_log_avg_like_count(posts):
    like_counts = [post.get("like_count", 0)  if post.get("like_count") is not None else 0 for post in posts]
    log_like_counts = np.log1p(like_counts)
    if not like_counts:
        return 0
    return sum(log_like_counts) / len(like_counts)

# Extract additional features from posts
def extract_features(post):
    # Hashtag count
    caption = post.get("caption", "") or ""
    hashtag_count = caption.count("#")

    # Caption length (in words)
    caption_length = len(caption.split())

    # Comments count
    comments_count = post.get("comments_count", 0)

    # Media type (one-hot encoded)
    media_type = post.get("media_type", "IMAGE")
    media_type_encoded = [1 if media_type == "IMAGE" else 0, 1 if media_type == "VIDEO" else 0]

    # Timestamp features
    timestamp = post.get("timestamp", "")
    if timestamp:
        dt = datetime.strptime(timestamp, "%Y-%m-%d %H:%M:%S")
        hour = dt.hour
        day_of_week = dt.weekday()
        month = dt.month
    else:
        hour = day_of_week = month = 0

    return [hashtag_count, caption_length, comments_count, hour, day_of_week, month] + media_type_encoded

# Prepare training data
features = []
log_avg_like_counts = []
log_like_counts = []
like_counts = []
for username, posts in username2posts_train.items():
    log_avg_like_count = get_log_avg_like_count(posts)
    for post in posts:
        like_count = post.get("like_count")
        features.append(extract_features(post))
        log_avg_like_counts.append(log_avg_like_count)
        if like_count is None:
          like_count = 0
        log_like_counts.append(np.log1p(like_count))
        like_counts.append(like_count)

# Convert features to numpy array
x_train = np.array(features)
log_avg_like_counts = np.array(log_avg_like_counts)
log_like_counts = np.array(log_like_counts)

from sklearn.linear_model import LinearRegression

# Train a linear regression model
regressor = LinearRegression()
regressor.fit(x_train, log_like_counts - log_avg_like_counts)

# Evaluate the model
y_train_pred_log_diff = regressor.predict(x_train)
y_train_pred_log = y_train_pred_log_diff + log_avg_like_counts
log_mse = mean_squared_error(log_like_counts, y_train_pred_log)
print(f"Training Log MSE: {log_mse}")

# Predict like count for a post
def predict_like_count(username, current_post=None):
    if username not in username2posts_train and username not in username2posts_test:
        print(f"No data available for {username}")
        return 0

    # Get the user's log average like count
    if username in username2posts_train:
        log_avg_like_count = get_log_avg_like_count(username2posts_train[username])
    elif username in username2posts_test:
        log_avg_like_count = get_log_avg_like_count(username2posts_test[username])

    # Extract features for the current post
    current_features = np.array([extract_features(current_post)])

    # Predict log-like count difference
    predicted_log_diff = regressor.predict(current_features)[0]

    # Reverse log transformation
    predicted_log_like_count = predicted_log_diff + log_avg_like_count
    if predicted_log_like_count < 0:
      predicted_log_like_count = 0
    predicted_like_count = np.expm1(predicted_log_like_count)

    return predicted_like_count

def log_mse_like_counts(y_true, y_pred):
  """
  Calculate the Log Mean Squared Error (Log MSE) for like counts (log(like_count + 1)).

  Parameters:
  - y_true: array-like, actual like counts
  - y_pred: array-like, predicted like counts

  Returns:
  - log_mse: float, Log Mean Squared Error
  """
  # Ensure inputs are numpy arrays
  y_true = np.array(y_true)
  y_pred = np.array(y_pred)

  # Log transformation: log(like_count + 1)
  log_y_true = np.log1p(y_true)
  log_y_pred = np.log1p(y_pred)

  # Compute squared errors
  squared_errors = (log_y_true - log_y_pred) ** 2

  # Return the mean of squared errors
  return np.mean(squared_errors)

#@title Train Dataset evaluation

y_like_count_train_true = []
y_like_count_train_pred = []
for uname, posts in username2posts_train.items():
  for post in posts:
    pred_val = predict_like_count(uname, post)
    true_val = post.get("like_count", 0)
    if true_val is None:
      true_val = 0

    y_like_count_train_true.append(true_val)
    y_like_count_train_pred.append(pred_val)

print(f"Log MSE Train= {log_mse_like_counts(y_like_count_train_true, y_like_count_train_pred)}")

#@title Test Dataset
def test_regression(input_file,output_file):
  path = "inputs/"+input_file
  output_path = "outputs/"+output_file

  to_predict_like_counts_usernames = []
  output_list = []
  with open(path, "rt") as fh:
    for line in fh:
      sample = json.loads(line)

      # let's predict
      pred_val = predict_like_count(sample["username"],sample)
      sample["like_count"] = int(pred_val)
      output_list.append(sample)

  with open(output_path, "wt") as of:
    json.dump(output_list, of)

test_regression("test-regression-round1.jsonl","prediction-regression-round1.json")
test_regression("test-regression-round2.jsonl","prediction-regression-round2.json")
test_regression("test-regression-round3.jsonl","prediction-regression-round3.json")